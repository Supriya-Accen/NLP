{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf idf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "text = [\"The amount of pollution is increasing day by day\",\n",
    "\"The concert was just great\", \"I love to see Gordon Ramsay cook\", \"Google is introducing a new technology\",\n",
    "\"AI Robots are examples of great technology present today\", \"All of us were singing in the concert\",\n",
    "\"We have launch campaigns to stop pullution and global warming\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_to_be_removed = list(stopwords.words(\"english\"))\n",
    "\n",
    "import nltk\n",
    "def cleaning(s):\n",
    "    s = s.lower()\n",
    "    text = nltk.tokenize.word_tokenize(s)\n",
    "    text = [t for t in text if len(t) > 2]\n",
    "    text = [t for t in text if not any (c.isdigit() for c in t)]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [cleaning(x) for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'amount', 'pollution', 'increasing', 'day', 'day'],\n",
       " ['the', 'concert', 'was', 'just', 'great'],\n",
       " ['love', 'see', 'gordon', 'ramsay', 'cook'],\n",
       " ['google', 'introducing', 'new', 'technology'],\n",
       " ['robots', 'are', 'examples', 'great', 'technology', 'present', 'today'],\n",
       " ['all', 'were', 'singing', 'the', 'concert'],\n",
       " ['have',\n",
       "  'launch',\n",
       "  'campaigns',\n",
       "  'stop',\n",
       "  'pullution',\n",
       "  'and',\n",
       "  'global',\n",
       "  'warming']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cleaned_texts=[]\n",
    "for x in text:\n",
    "    final_cleaned_texts.append(''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T h e   a m o u n t   o f   p o l l u t i o n   i s   i n c r e a s i n g   d a y   b y   d a y',\n",
       " 'T h e   c o n c e r t   w a s   j u s t   g r e a t',\n",
       " 'I   l o v e   t o   s e e   G o r d o n   R a m s a y   c o o k',\n",
       " 'G o o g l e   i s   i n t r o d u c i n g   a   n e w   t e c h n o l o g y',\n",
       " 'A I   R o b o t s   a r e   e x a m p l e s   o f   g r e a t   t e c h n o l o g y   p r e s e n t   t o d a y',\n",
       " 'A l l   o f   u s   w e r e   s i n g i n g   i n   t h e   c o n c e r t',\n",
       " 'W e   h a v e   l a u n c h   c a m p a i g n s   t o   s t o p   p u l l u t i o n   a n d   g l o b a l   w a r m i n g']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x26 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 29 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tfidf.fit_transform(final_cleaned_texts)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.81649658,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.40824829, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.53828134, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.53828134,\n",
       "        0.        , 0.        , 0.64846464, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.52064676, 0.        , 0.        ,\n",
       "        0.        , 0.52064676, 0.        , 0.        , 0.        ,\n",
       "        0.52064676, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.43218152, 0.        ,\n",
       "        0.        ],\n",
       "       [0.39596322, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.39596322, 0.        , 0.        , 0.        , 0.32868348,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.39596322, 0.        , 0.        ,\n",
       "        0.39596322, 0.        , 0.        , 0.32868348, 0.39596322,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.63870855, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.76944876, 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40824829, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40824829, 0.        ,\n",
       "        0.        , 0.        , 0.40824829, 0.        , 0.        ,\n",
       "        0.40824829]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3099229565220925\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean, cdist, pdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "\n",
    "print(euclidean(a[3], a[4])) #Euclidean distance-distance between 2 points;pythagoras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentimental analysis-vader-pre trained models-assumes ur data as test data; \n",
    "#therefore different models give diff sentimental analysis\n",
    "#textblob\n",
    "#spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
